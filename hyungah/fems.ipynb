{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9012f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ffa1222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>Temp. ave.</th>\n",
       "      <th>Humidity ave.</th>\n",
       "      <th>product_1</th>\n",
       "      <th>product_2</th>\n",
       "      <th>product_total</th>\n",
       "      <th>Usage_power_1</th>\n",
       "      <th>Usage_power_2</th>\n",
       "      <th>Usage_power_total</th>\n",
       "      <th>Usage_LNG_1</th>\n",
       "      <th>Usage_LNG_2</th>\n",
       "      <th>Usage_LNG_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>56</td>\n",
       "      <td>458.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>131076.0</td>\n",
       "      <td>208894.0</td>\n",
       "      <td>339970.0</td>\n",
       "      <td>30701.0</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>71302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>345.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>126691.0</td>\n",
       "      <td>165730.0</td>\n",
       "      <td>292421.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60063.0</td>\n",
       "      <td>60065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>5.3</td>\n",
       "      <td>51</td>\n",
       "      <td>451.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>108115.0</td>\n",
       "      <td>153727.0</td>\n",
       "      <td>261842.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74865.0</td>\n",
       "      <td>74865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>13.3</td>\n",
       "      <td>50</td>\n",
       "      <td>408.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>134957.0</td>\n",
       "      <td>215309.0</td>\n",
       "      <td>350266.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68629.0</td>\n",
       "      <td>68629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>18.3</td>\n",
       "      <td>53</td>\n",
       "      <td>474.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>122889.0</td>\n",
       "      <td>236801.0</td>\n",
       "      <td>359690.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>66621.0</td>\n",
       "      <td>67471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>21.2</td>\n",
       "      <td>59</td>\n",
       "      <td>458.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>139723.0</td>\n",
       "      <td>259740.0</td>\n",
       "      <td>399463.0</td>\n",
       "      <td>3788.0</td>\n",
       "      <td>60659.0</td>\n",
       "      <td>64447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>23.8</td>\n",
       "      <td>78</td>\n",
       "      <td>426.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>159553.0</td>\n",
       "      <td>237327.0</td>\n",
       "      <td>396880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63114.0</td>\n",
       "      <td>63114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>18.4</td>\n",
       "      <td>74</td>\n",
       "      <td>492.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>164397.0</td>\n",
       "      <td>258803.0</td>\n",
       "      <td>423200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71470.0</td>\n",
       "      <td>71470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>13.7</td>\n",
       "      <td>74</td>\n",
       "      <td>366.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>136707.0</td>\n",
       "      <td>218239.0</td>\n",
       "      <td>354946.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60119.0</td>\n",
       "      <td>60119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>4.6</td>\n",
       "      <td>59</td>\n",
       "      <td>437.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>125740.0</td>\n",
       "      <td>207692.0</td>\n",
       "      <td>333432.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60930.0</td>\n",
       "      <td>60937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>53</td>\n",
       "      <td>315.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>111738.0</td>\n",
       "      <td>168192.0</td>\n",
       "      <td>279930.0</td>\n",
       "      <td>27650.0</td>\n",
       "      <td>29998.0</td>\n",
       "      <td>57648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>52</td>\n",
       "      <td>396.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>109181.0</td>\n",
       "      <td>143497.0</td>\n",
       "      <td>252678.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71215.0</td>\n",
       "      <td>71215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>40</td>\n",
       "      <td>310.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>124207.0</td>\n",
       "      <td>170640.0</td>\n",
       "      <td>294847.0</td>\n",
       "      <td>19909.0</td>\n",
       "      <td>36374.0</td>\n",
       "      <td>56283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>7.3</td>\n",
       "      <td>58</td>\n",
       "      <td>359.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>103580.0</td>\n",
       "      <td>138852.0</td>\n",
       "      <td>242432.0</td>\n",
       "      <td>23323.0</td>\n",
       "      <td>36259.0</td>\n",
       "      <td>59582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>12.8</td>\n",
       "      <td>54</td>\n",
       "      <td>462.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>128239.0</td>\n",
       "      <td>198871.0</td>\n",
       "      <td>327110.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>72160.0</td>\n",
       "      <td>72777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>17.1</td>\n",
       "      <td>66</td>\n",
       "      <td>517.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>153807.0</td>\n",
       "      <td>223877.0</td>\n",
       "      <td>377684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72504.0</td>\n",
       "      <td>72504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>21.9</td>\n",
       "      <td>63</td>\n",
       "      <td>507.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>173440.0</td>\n",
       "      <td>257508.0</td>\n",
       "      <td>430948.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>64052.0</td>\n",
       "      <td>64633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>26.0</td>\n",
       "      <td>72</td>\n",
       "      <td>488.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>185610.0</td>\n",
       "      <td>255916.0</td>\n",
       "      <td>441526.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65911.0</td>\n",
       "      <td>65911.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>25.3</td>\n",
       "      <td>74</td>\n",
       "      <td>446.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>203853.0</td>\n",
       "      <td>234374.0</td>\n",
       "      <td>438227.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>62405.0</td>\n",
       "      <td>62494.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>18.2</td>\n",
       "      <td>74</td>\n",
       "      <td>489.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>202025.0</td>\n",
       "      <td>254512.0</td>\n",
       "      <td>456537.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>65770.0</td>\n",
       "      <td>67112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>11.0</td>\n",
       "      <td>69</td>\n",
       "      <td>514.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>158875.0</td>\n",
       "      <td>198713.0</td>\n",
       "      <td>357588.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>74919.0</td>\n",
       "      <td>74966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>5.8</td>\n",
       "      <td>68</td>\n",
       "      <td>537.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>166997.0</td>\n",
       "      <td>214114.0</td>\n",
       "      <td>381111.0</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>77563.0</td>\n",
       "      <td>78674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>466.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>152050.0</td>\n",
       "      <td>176248.0</td>\n",
       "      <td>328298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75155.0</td>\n",
       "      <td>75155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>49</td>\n",
       "      <td>492.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>155016.0</td>\n",
       "      <td>158156.0</td>\n",
       "      <td>313172.0</td>\n",
       "      <td>7127.0</td>\n",
       "      <td>78351.0</td>\n",
       "      <td>85478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1.1</td>\n",
       "      <td>52</td>\n",
       "      <td>357.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>144634.0</td>\n",
       "      <td>153115.0</td>\n",
       "      <td>297749.0</td>\n",
       "      <td>15519.0</td>\n",
       "      <td>46772.0</td>\n",
       "      <td>62291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56</td>\n",
       "      <td>490.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>122169.0</td>\n",
       "      <td>149825.0</td>\n",
       "      <td>271994.0</td>\n",
       "      <td>70124.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>11.1</td>\n",
       "      <td>56</td>\n",
       "      <td>557.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>157997.0</td>\n",
       "      <td>198137.0</td>\n",
       "      <td>356134.0</td>\n",
       "      <td>44971.0</td>\n",
       "      <td>29054.0</td>\n",
       "      <td>74025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>18.1</td>\n",
       "      <td>51</td>\n",
       "      <td>522.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>173369.0</td>\n",
       "      <td>228909.0</td>\n",
       "      <td>402278.0</td>\n",
       "      <td>7591.0</td>\n",
       "      <td>63812.0</td>\n",
       "      <td>71403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>20.9</td>\n",
       "      <td>68</td>\n",
       "      <td>450.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>177112.0</td>\n",
       "      <td>237579.0</td>\n",
       "      <td>414691.0</td>\n",
       "      <td>14070.0</td>\n",
       "      <td>52448.0</td>\n",
       "      <td>66518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>23.6</td>\n",
       "      <td>77</td>\n",
       "      <td>493.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>175154.0</td>\n",
       "      <td>211723.0</td>\n",
       "      <td>386877.0</td>\n",
       "      <td>10437.0</td>\n",
       "      <td>53782.0</td>\n",
       "      <td>64219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>24.5</td>\n",
       "      <td>75</td>\n",
       "      <td>466.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>191909.0</td>\n",
       "      <td>235750.0</td>\n",
       "      <td>427659.0</td>\n",
       "      <td>1278.0</td>\n",
       "      <td>61268.0</td>\n",
       "      <td>62546.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>20.1</td>\n",
       "      <td>78</td>\n",
       "      <td>444.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>173729.0</td>\n",
       "      <td>226109.0</td>\n",
       "      <td>399838.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61833.0</td>\n",
       "      <td>61833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>13.9</td>\n",
       "      <td>72</td>\n",
       "      <td>531.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>164520.0</td>\n",
       "      <td>208621.0</td>\n",
       "      <td>373141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71778.0</td>\n",
       "      <td>71778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>6.5</td>\n",
       "      <td>67</td>\n",
       "      <td>474.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>162834.0</td>\n",
       "      <td>219686.0</td>\n",
       "      <td>382520.0</td>\n",
       "      <td>16268.0</td>\n",
       "      <td>56476.0</td>\n",
       "      <td>72744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>65</td>\n",
       "      <td>428.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>140854.0</td>\n",
       "      <td>183765.0</td>\n",
       "      <td>324619.0</td>\n",
       "      <td>13490.0</td>\n",
       "      <td>53901.0</td>\n",
       "      <td>67391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1.4</td>\n",
       "      <td>67</td>\n",
       "      <td>436.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>128672.0</td>\n",
       "      <td>155866.0</td>\n",
       "      <td>284538.0</td>\n",
       "      <td>21408.0</td>\n",
       "      <td>45057.0</td>\n",
       "      <td>66465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2.1</td>\n",
       "      <td>65</td>\n",
       "      <td>320.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>119671.0</td>\n",
       "      <td>166651.0</td>\n",
       "      <td>286322.0</td>\n",
       "      <td>19686.0</td>\n",
       "      <td>36530.0</td>\n",
       "      <td>56216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>7.2</td>\n",
       "      <td>57</td>\n",
       "      <td>380.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>115459.0</td>\n",
       "      <td>153403.0</td>\n",
       "      <td>268862.0</td>\n",
       "      <td>22259.0</td>\n",
       "      <td>41124.0</td>\n",
       "      <td>63383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>10.3</td>\n",
       "      <td>50</td>\n",
       "      <td>462.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>117266.0</td>\n",
       "      <td>174715.0</td>\n",
       "      <td>291981.0</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>68271.0</td>\n",
       "      <td>70008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>17.1</td>\n",
       "      <td>69</td>\n",
       "      <td>377.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>131594.0</td>\n",
       "      <td>189720.0</td>\n",
       "      <td>321314.0</td>\n",
       "      <td>14030.0</td>\n",
       "      <td>44025.0</td>\n",
       "      <td>58055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>22.5</td>\n",
       "      <td>72</td>\n",
       "      <td>398.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>148442.0</td>\n",
       "      <td>197755.0</td>\n",
       "      <td>346197.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56418.0</td>\n",
       "      <td>56422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>21.7</td>\n",
       "      <td>87</td>\n",
       "      <td>424.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>157334.0</td>\n",
       "      <td>207971.0</td>\n",
       "      <td>365305.0</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>58533.0</td>\n",
       "      <td>62892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>89</td>\n",
       "      <td>381.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>176624.0</td>\n",
       "      <td>224063.0</td>\n",
       "      <td>400687.0</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>50599.0</td>\n",
       "      <td>52850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>18.7</td>\n",
       "      <td>81</td>\n",
       "      <td>444.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>170230.0</td>\n",
       "      <td>212458.0</td>\n",
       "      <td>382688.0</td>\n",
       "      <td>4892.0</td>\n",
       "      <td>58247.0</td>\n",
       "      <td>63139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>12.1</td>\n",
       "      <td>70</td>\n",
       "      <td>407.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>148327.0</td>\n",
       "      <td>173837.0</td>\n",
       "      <td>322164.0</td>\n",
       "      <td>6005.0</td>\n",
       "      <td>52381.0</td>\n",
       "      <td>58386.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         month  Temp. ave.  Humidity ave.  product_1  product_2  \\\n",
       "0   2017-01-01        -1.7             56      458.0      197.0   \n",
       "1   2017-02-01         0.1             52      345.0      180.0   \n",
       "2   2017-03-01         5.3             51      451.0      236.0   \n",
       "3   2017-04-01        13.3             50      408.0      220.0   \n",
       "4   2017-05-01        18.3             53      474.0      224.0   \n",
       "5   2017-06-01        21.2             59      458.0      196.0   \n",
       "7   2017-08-01        23.8             78      426.0      214.0   \n",
       "8   2017-09-01        18.4             74      492.0      197.0   \n",
       "9   2017-10-01        13.7             74      366.0      171.0   \n",
       "10  2017-11-01         4.6             59      437.0      196.0   \n",
       "11  2017-12-01        -2.5             53      315.0      159.0   \n",
       "12  2018-01-01        -3.9             52      396.0      194.0   \n",
       "13  2018-02-01        -1.6             40      310.0      147.0   \n",
       "14  2018-03-01         7.3             58      359.0      169.0   \n",
       "15  2018-04-01        12.8             54      462.0      191.0   \n",
       "16  2018-05-01        17.1             66      517.0      192.0   \n",
       "17  2018-06-01        21.9             63      507.0      172.0   \n",
       "18  2018-07-01        26.0             72      488.0      173.0   \n",
       "19  2018-08-01        25.3             74      446.0      185.0   \n",
       "20  2018-09-01        18.2             74      489.0      162.0   \n",
       "21  2018-10-01        11.0             69      514.0      193.0   \n",
       "22  2018-11-01         5.8             68      537.0      170.0   \n",
       "23  2018-12-01        -1.0             55      466.0      164.0   \n",
       "24  2019-01-01        -1.5             49      492.0      168.0   \n",
       "25  2019-02-01         1.1             52      357.0      120.0   \n",
       "26  2019-03-01         6.0             56      490.0      158.0   \n",
       "27  2019-04-01        11.1             56      557.0      163.0   \n",
       "28  2019-05-01        18.1             51      522.0      159.0   \n",
       "29  2019-06-01        20.9             68      450.0      141.0   \n",
       "30  2019-07-01        23.6             77      493.0      162.0   \n",
       "31  2019-08-01        24.5             75      466.0      152.0   \n",
       "32  2019-09-01        20.1             78      444.0      139.0   \n",
       "33  2019-10-01        13.9             72      531.0      165.0   \n",
       "34  2019-11-01         6.5             67      474.0      180.0   \n",
       "35  2019-12-01         0.5             65      428.0      134.0   \n",
       "36  2020-01-01         1.4             67      436.0      145.0   \n",
       "37  2020-02-01         2.1             65      320.0      116.0   \n",
       "38  2020-03-01         7.2             57      380.0      137.0   \n",
       "39  2020-04-01        10.3             50      462.0      146.0   \n",
       "40  2020-05-01        17.1             69      377.0      112.0   \n",
       "41  2020-06-01        22.5             72      398.0      128.0   \n",
       "42  2020-07-01        21.7             87      424.0      120.0   \n",
       "43  2020-08-01        25.0             89      381.0      131.0   \n",
       "44  2020-09-01        18.7             81      444.0      142.0   \n",
       "45  2020-10-01        12.1             70      407.0      127.0   \n",
       "\n",
       "    product_total  Usage_power_1  Usage_power_2  Usage_power_total  \\\n",
       "0           655.0       131076.0       208894.0           339970.0   \n",
       "1           525.0       126691.0       165730.0           292421.0   \n",
       "2           687.0       108115.0       153727.0           261842.0   \n",
       "3           628.0       134957.0       215309.0           350266.0   \n",
       "4           698.0       122889.0       236801.0           359690.0   \n",
       "5           654.0       139723.0       259740.0           399463.0   \n",
       "7           640.0       159553.0       237327.0           396880.0   \n",
       "8           689.0       164397.0       258803.0           423200.0   \n",
       "9           537.0       136707.0       218239.0           354946.0   \n",
       "10          633.0       125740.0       207692.0           333432.0   \n",
       "11          474.0       111738.0       168192.0           279930.0   \n",
       "12          590.0       109181.0       143497.0           252678.0   \n",
       "13          457.0       124207.0       170640.0           294847.0   \n",
       "14          528.0       103580.0       138852.0           242432.0   \n",
       "15          653.0       128239.0       198871.0           327110.0   \n",
       "16          709.0       153807.0       223877.0           377684.0   \n",
       "17          679.0       173440.0       257508.0           430948.0   \n",
       "18          661.0       185610.0       255916.0           441526.0   \n",
       "19          631.0       203853.0       234374.0           438227.0   \n",
       "20          651.0       202025.0       254512.0           456537.0   \n",
       "21          707.0       158875.0       198713.0           357588.0   \n",
       "22          707.0       166997.0       214114.0           381111.0   \n",
       "23          630.0       152050.0       176248.0           328298.0   \n",
       "24          660.0       155016.0       158156.0           313172.0   \n",
       "25          477.0       144634.0       153115.0           297749.0   \n",
       "26          648.0       122169.0       149825.0           271994.0   \n",
       "27          720.0       157997.0       198137.0           356134.0   \n",
       "28          681.0       173369.0       228909.0           402278.0   \n",
       "29          591.0       177112.0       237579.0           414691.0   \n",
       "30          655.0       175154.0       211723.0           386877.0   \n",
       "31          618.0       191909.0       235750.0           427659.0   \n",
       "32          583.0       173729.0       226109.0           399838.0   \n",
       "33          696.0       164520.0       208621.0           373141.0   \n",
       "34          654.0       162834.0       219686.0           382520.0   \n",
       "35          562.0       140854.0       183765.0           324619.0   \n",
       "36          581.0       128672.0       155866.0           284538.0   \n",
       "37          436.0       119671.0       166651.0           286322.0   \n",
       "38          517.0       115459.0       153403.0           268862.0   \n",
       "39          608.0       117266.0       174715.0           291981.0   \n",
       "40          489.0       131594.0       189720.0           321314.0   \n",
       "41          526.0       148442.0       197755.0           346197.0   \n",
       "42          544.0       157334.0       207971.0           365305.0   \n",
       "43          512.0       176624.0       224063.0           400687.0   \n",
       "44          586.0       170230.0       212458.0           382688.0   \n",
       "45          534.0       148327.0       173837.0           322164.0   \n",
       "\n",
       "    Usage_LNG_1  Usage_LNG_2  Usage_LNG_total  \n",
       "0       30701.0      40601.0          71302.0  \n",
       "1           2.0      60063.0          60065.0  \n",
       "2           0.0      74865.0          74865.0  \n",
       "3           0.0      68629.0          68629.0  \n",
       "4         850.0      66621.0          67471.0  \n",
       "5        3788.0      60659.0          64447.0  \n",
       "7           0.0      63114.0          63114.0  \n",
       "8           0.0      71470.0          71470.0  \n",
       "9           0.0      60119.0          60119.0  \n",
       "10          7.0      60930.0          60937.0  \n",
       "11      27650.0      29998.0          57648.0  \n",
       "12          0.0      71215.0          71215.0  \n",
       "13      19909.0      36374.0          56283.0  \n",
       "14      23323.0      36259.0          59582.0  \n",
       "15        617.0      72160.0          72777.0  \n",
       "16          0.0      72504.0          72504.0  \n",
       "17        581.0      64052.0          64633.0  \n",
       "18          0.0      65911.0          65911.0  \n",
       "19         89.0      62405.0          62494.0  \n",
       "20       1342.0      65770.0          67112.0  \n",
       "21         47.0      74919.0          74966.0  \n",
       "22       1111.0      77563.0          78674.0  \n",
       "23          0.0      75155.0          75155.0  \n",
       "24       7127.0      78351.0          85478.0  \n",
       "25      15519.0      46772.0          62291.0  \n",
       "26      70124.0         20.0          70144.0  \n",
       "27      44971.0      29054.0          74025.0  \n",
       "28       7591.0      63812.0          71403.0  \n",
       "29      14070.0      52448.0          66518.0  \n",
       "30      10437.0      53782.0          64219.0  \n",
       "31       1278.0      61268.0          62546.0  \n",
       "32          0.0      61833.0          61833.0  \n",
       "33          0.0      71778.0          71778.0  \n",
       "34      16268.0      56476.0          72744.0  \n",
       "35      13490.0      53901.0          67391.0  \n",
       "36      21408.0      45057.0          66465.0  \n",
       "37      19686.0      36530.0          56216.0  \n",
       "38      22259.0      41124.0          63383.0  \n",
       "39       1737.0      68271.0          70008.0  \n",
       "40      14030.0      44025.0          58055.0  \n",
       "41          4.0      56418.0          56422.0  \n",
       "42       4359.0      58533.0          62892.0  \n",
       "43       2251.0      50599.0          52850.0  \n",
       "44       4892.0      58247.0          63139.0  \n",
       "45       6005.0      52381.0          58386.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fems_df = pd.read_csv('dataset.csv')\n",
    "# print(fems_df)\n",
    "fems_df.dropna(inplace=True)\n",
    "fems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f2555c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 12)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fems_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024356ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "fems_csv = pd.read_csv('dataset.csv', header=None, skiprows=1).values\n",
    "fems_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95ad39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "544cdd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: feature, y: label\n",
    "\n",
    "X = fems_df[ ['Temp. ave.', 'Humidity ave.', 'product_1', 'product_2', 'product_total'] ]\n",
    "y = fems_df[ ['Usage_power_1', 'Usage_power_2', 'Usage_power_total', 'Usage_LNG_1', 'Usage_LNG_2', 'Usage_LNG_total'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "964c295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fems_df_val = fems_df.values\n",
    "X = fems_df_val[:,:4]\n",
    "y = fems_df_val[:,5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a888fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8ff473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 4) (14, 4) (31, 7) (14, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56b93dcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 12)                72        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               3328      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 4,942\n",
      "Trainable params: 4,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(12, activation='relu', input_dim=5))\n",
    "mlp_model.add(Dense(256, activation='relu'))\n",
    "mlp_model.add(Dense(6, activation='softmax'))\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "159973e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.005)\n",
    "\n",
    "mlp_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c4f2fa57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-ee2396c22b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'정확도는 {}% 입니다.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_data_adapter_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1155\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m                **kwargs):\n\u001b[1;32m    246\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    249\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "model_history = mlp_model.fit(X_train, y_train, epochs=15, batch_size=256, verbose=0, validation_data=(X_test, y_test), shuffle=True)\n",
    "score = mlp_model.evaluate(X_test, y_test)\n",
    "print('정확도는 {}% 입니다.'.format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026462e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
